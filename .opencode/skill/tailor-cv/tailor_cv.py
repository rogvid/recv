#!/usr/bin/env python3
"""
CV Tailoring Agent
Analyzes job descriptions and generates tailored CV configurations
"""

import sys
import re
import os
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import json
from urllib.parse import urlparse

# This script will be called by the OpenCode skill
# It performs the heavy lifting of analyzing job descriptions and matching resources


def slugify(text: str) -> str:
    """Convert text to URL-friendly slug"""
    text = text.lower()
    text = re.sub(r"[^\w\s-]", "", text)
    text = re.sub(r"[-\s]+", "-", text)
    return text.strip("-")


def extract_job_info(job_description: str) -> Dict:
    """
    Extract key information from job description
    Uses pattern matching and keyword extraction
    """
    info = {
        "title": "",
        "company": "",
        "keywords": [],
        "required_skills": [],
        "nice_to_have_skills": [],
        "experience_level": "",
        "responsibilities": [],
    }

    # This is a simplified version - the actual LLM agent will do this
    # For now, we'll use basic pattern matching

    lines = job_description.split("\n")
    for line in lines:
        # Extract title (usually first meaningful line or has "position", "role", "job title")
        if not info["title"] and any(
            keyword in line.lower()
            for keyword in ["position", "role", "job title", "we are looking for"]
        ):
            info["title"] = line.strip()

    return info


def load_work_resources() -> List[Dict]:
    """Load all work experience resources"""
    work_dir = Path("resources/work")
    resources = []

    for file in sorted(work_dir.glob("*.typ"), reverse=True):
        # Parse the .typ file to extract job data
        # This is simplified - the actual implementation would properly parse Typst
        resources.append(
            {
                "filename": file.name,
                "path": str(file),
            }
        )

    return resources


def load_education_resources() -> Dict[str, List[Dict]]:
    """Load all education resources"""
    edu_dir = Path("resources/education")
    resources = {
        "degrees": [],
        "certificates": [],
        "courses": [],
    }

    for file in sorted(edu_dir.glob("degree-*.typ")):
        resources["degrees"].append({"filename": file.name, "path": str(file)})

    for file in sorted(edu_dir.glob("cert-*.typ")):
        resources["certificates"].append({"filename": file.name, "path": str(file)})

    for file in sorted(edu_dir.glob("course-*.typ")):
        resources["courses"].append({"filename": file.name, "path": str(file)})

    return resources


def rank_work_experiences(job_info: Dict, work_resources: List[Dict]) -> List[Dict]:
    """
    Rank work experiences by relevance to job
    Returns sorted list with relevance scores
    """
    # This will be implemented by the LLM agent
    # For now, return top N
    return work_resources[:3]


def generate_config(
    job_slug: str, job_info: Dict, selected_work: List[Dict], selected_edu: Dict
) -> str:
    """Generate Typst configuration file content"""

    config_content = f'''// config/tailored/{job_slug}-config.typ
// Auto-generated configuration for: {job_info.get("title", "Unknown Position")}
// Generated by tailor-cv skill

#let cv_config = (
  // Target job profile
  target: (
    position: "{job_info.get("title", "Position")}",
    company: "{job_info.get("company", "")}",
    keywords: {tuple(job_info.get("keywords", []))},
  ),
  
  // Work experiences (in display order - most recent first)
  work: (
'''

    for work in selected_work:
        config_content += f'    "{work["filename"]}",\n'

    config_content += """  ),
  
  // Education
  education: (
    degrees: (
"""

    for degree in selected_edu.get("degrees", [])[:2]:
        config_content += f'      "{degree["filename"]}",\n'

    config_content += """    ),
    certificates: (
"""

    for cert in selected_edu.get("certificates", [])[:2]:
        config_content += f'      "{cert["filename"]}",\n'

    config_content += """    ),
  ),
  
  // Accomplishment selection criteria
  accomplishments: (
    max_per_job: 3,                      // Top 3 per job for OP_CV
    min_impact: "high",                   // Only high-impact achievements
    prioritize_quantifiable: true,        // Prefer metrics/numbers
    required_tags: (),                    // Tags that must be present
  ),
  
  // ATS-specific settings
  ats: (
    max_per_job: 4,                      // More accomplishments for ATS
    min_impact: "medium",                 // Include medium impact
    keyword_optimization: true,           // Optimize for ATS keywords
  ),
)
"""

    return config_content


def main():
    if len(sys.argv) < 2:
        print("Usage: python tailor_cv.py <job_description_file_or_url> [job_name]")
        sys.exit(1)

    job_input = sys.argv[1]
    custom_job_name = sys.argv[2] if len(sys.argv) > 2 else None

    # Determine if input is URL or file
    parsed = urlparse(job_input)
    is_url = parsed.scheme in ("http", "https")

    if is_url:
        print(f"Fetching job description from URL: {job_input}")
        # Will be handled by the skill using webfetch
        print("ERROR: URL fetching should be handled by the OpenCode skill")
        sys.exit(1)
    else:
        print(f"Reading job description from file: {job_input}")
        with open(job_input, "r") as f:
            job_description = f.read()

    # Extract job information
    print("\nAnalyzing job description...")
    job_info = extract_job_info(job_description)

    # Generate job slug
    if custom_job_name:
        job_slug = slugify(custom_job_name)
    elif job_info.get("title"):
        job_slug = slugify(job_info["title"])
    else:
        job_slug = "tailored-cv"

    print(f"Job slug: {job_slug}")

    # Load resources
    print("\nLoading work experience resources...")
    work_resources = load_work_resources()
    print(f"Found {len(work_resources)} work experiences")

    print("\nLoading education resources...")
    edu_resources = load_education_resources()
    print(
        f"Found {len(edu_resources['degrees'])} degrees, {len(edu_resources['certificates'])} certificates"
    )

    # Rank and select
    print("\nRanking work experiences by relevance...")
    selected_work = rank_work_experiences(job_info, work_resources)

    # Generate config
    print(f"\nGenerating configuration file...")
    config_content = generate_config(job_slug, job_info, selected_work, edu_resources)

    # Create output directories
    os.makedirs("config/tailored", exist_ok=True)
    os.makedirs("templates/tailored", exist_ok=True)
    os.makedirs(f"builds/{job_slug}", exist_ok=True)

    # Write config
    config_path = f"config/tailored/{job_slug}-config.typ"
    with open(config_path, "w") as f:
        f.write(config_content)
    print(f"✓ Created: {config_path}")

    # Save job description
    job_desc_path = f"builds/{job_slug}/job-description.txt"
    with open(job_desc_path, "w") as f:
        f.write(job_description)
    print(f"✓ Saved: {job_desc_path}")

    print(f"\n{'=' * 60}")
    print(f"Configuration generated successfully!")
    print(f"Job slug: {job_slug}")
    print(f"Selected {len(selected_work)} work experiences")
    print(f"{'=' * 60}")


if __name__ == "__main__":
    main()
